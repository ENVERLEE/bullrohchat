# main.py
import os
import argparse
import hashlib
from dotenv import load_dotenv
from tqdm import tqdm
import oracledb
import urllib.parse # Add this import
import json
import numpy as np # Add this import
from database import OracleManager
from crawler import BlogCrawler
from embedder import Embedder
from chatbot_service import ChatbotService

def clear_screen():
    os.system('cls' if os.name == 'nt' else 'clear')

def onboard_command():
    clear_screen(); print("="*50 + "\n       <ë¶ˆë¡œì±—> AI ì±—ë´‡ ì˜¨ë³´ë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n" + "="*50)
    db = OracleManager()
    existing_info = db.get_business_info()
    if existing_info:
        print("\n[ì•Œë¦¼] ê¸°ì¡´ì— ì €ì¥ëœ ì •ë³´ê°€ ìˆìŠµë‹ˆë‹¤. ë‚´ìš©ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.")
        default_name = existing_info.get('business_name', '')
        default_url = existing_info.get('blog_url', '')
    else:
        print("\n[ì•ˆë‚´] ì—…ì²´ ì •ë³´ì™€ ì±—ë´‡ ì„¤ì •ì„ ìœ„í•´ ëª‡ ê°€ì§€ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.")
        default_name, default_url = "", ""
    business_name = input(f"\n1. ì—…ì²´ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ê¸°ë³¸ê°’: {default_name}): ") or default_name
    blog_url = input(f"2. ì •ë³´ ê¸°ë°˜ì´ ë  ë„¤ì´ë²„ ë¸”ë¡œê·¸ URLì„ ì…ë ¥í•˜ì„¸ìš” (ê¸°ë³¸ê°’: {default_url}): ") or default_url
    chatbot_personality = input("3. ì±—ë´‡ì˜ ì„±ê²©ì„ ì„¤ì •í•´ì£¼ì„¸ìš” (ì˜ˆ: ì¹œì ˆí•˜ê³  ìƒëƒ¥í•˜ê²Œ): ")
    faqs = []
    print("\n4. ìì£¼ ë¬»ëŠ” ì§ˆë¬¸(FAQ)ì„ ì¶”ê°€í•©ë‹ˆë‹¤ (ì™„ë£Œ ì‹œ ê·¸ëƒ¥ Enter).")
    while True:
        q = input("  - ì§ˆë¬¸(Q): ");
        if not q: break
        a = input(f"  - ë‹µë³€(A) for '{q}': "); faqs.append({'q': q, 'a': a})
    marketing_info = input("\n5. í˜„ì¬ ì§„í–‰ì¤‘ì¸ ì´ë²¤íŠ¸ë‚˜ ë§ˆì¼€íŒ… ë¬¸êµ¬ê°€ ìˆë‚˜ìš”? ")
    info = {'business_name': business_name, 'blog_url': blog_url, 'chatbot_personality': chatbot_personality, 'faqs': faqs, 'marketing_info': marketing_info}
    db.save_business_info(info); db.close()
    print("\n" + "="*50 + "\nğŸ‰ ì˜¨ë³´ë”©ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n" + "="*50)

def crawl_command(args):
    db = OracleManager()
    info = db.get_business_info()
    if not info or not info.get('blog_url'):
        print("âŒ ë¸”ë¡œê·¸ URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'onboard' ëª…ë ¹ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”."); db.close(); return
    print(f"â–¶ï¸ '{info['business_name']}'ì˜ ë¸”ë¡œê·¸({info['blog_url']}) í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.");
    crawler = BlogCrawler(); embedder = Embedder()
    
    # max_posts ì¸ìë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
    max_posts_to_crawl = args.max_posts if hasattr(args, 'max_posts') else None
    all_posts_meta = crawler.crawl_all_posts(info['blog_url'], max_posts=max_posts_to_crawl)
    
    if not all_posts_meta:
        print("âš ï¸ í¬ë¡¤ë§í•  ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤."); crawler.close(); db.close(); return
        
    for post_meta in tqdm(all_posts_meta, desc="ê²Œì‹œê¸€ ì²˜ë¦¬ ì¤‘"):
        # URL ë””ì½”ë”©ëœ ì œëª©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        decoded_title = urllib.parse.unquote(post_meta['title'])
        try:
            content_data = crawler.crawl_post_content(post_meta['url'])
            if not content_data:
                tqdm.write(f"  - ì½˜í…ì¸  ì—†ìŒ: '{decoded_title}' ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            # content_dataê°€ ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì¸ì½”ë”©í•©ë‹ˆë‹¤.
            # ì´ì „ì— 'dict' object has no attribute 'encode' ì˜¤ë¥˜ê°€ ë°œìƒí•œ ë¶€ë¶„ì…ë‹ˆë‹¤.
            content_text_for_hash = json.dumps(content_data, ensure_ascii=False)
            new_hash = hashlib.sha256(content_text_for_hash.encode('utf-8')).hexdigest()
            old_hash = db.get_post_hash(post_meta['url'])
            
            # ì„ë² ë”©ì„ ìœ„í•´ ì‹¤ì œ í…ìŠ¤íŠ¸ ì½˜í…ì¸ ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            content_for_embedding = content_data.get('content', '')

            if new_hash == old_hash:
                tqdm.write(f"  - [ë³€ê²½ ì—†ìŒ] '{decoded_title}' ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            
            tqdm.write(f"  - [ì½˜í…ì¸  ë³€ê²½ ê°ì§€] '{decoded_title}' ì²˜ë¦¬ ì‹œì‘...")
            chunks = embedder.split_text(content_for_embedding)
            embeddings = embedder.embed_texts(chunks) # <- ë³€ê²½ëœ ê²½ìš°ì—ë§Œ API í˜¸ì¶œ
            # embeddingsëŠ” ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ì˜ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ, .tolist()ë¥¼ ë‹¤ì‹œ í˜¸ì¶œí•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.
            chunks_with_embeddings = [{"chunk_text": text, "embedding": emb} for text, emb in zip(chunks, embeddings)]
            db.upsert_post_with_chunks(post_meta['url'], post_meta['title'], new_hash, chunks_with_embeddings)
        except Exception as e:
            tqdm.write(f"  - âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {post_meta['url']}, {e}")
            
    crawler.close(); db.close()
    print("\nğŸ‰ ë¸”ë¡œê·¸ ì „ì²´ ë°ì´í„°í™” ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

def ask_command(question: str):
    db = OracleManager(); embedder = Embedder()
    chatbot = ChatbotService(db, embedder)
    print("\nğŸ¤” AI ì±—ë´‡ì´ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
    answer = chatbot.answer_question(question)
    print("\n" + "="*50 + f"\nğŸ‘¤ ê³ ê° ì§ˆë¬¸: {question}\n" + " ="*50)
    print(f"\nğŸ¤– <ë¶ˆë¡œì±—> ë‹µë³€:\n\n{answer}\n\n" + "="*50)
    db.close()

def main():
    load_dotenv()
    parser = argparse.ArgumentParser(description="<ë¶ˆë¡œì±—> ì†Œìƒê³µì¸ AI ì±—ë´‡ ìë™í™” í”Œë«í¼ (ë¹„ìš© ìµœì í™” ë²„ì „)")
    subparsers = parser.add_subparsers(dest="command", required=True)
    subparsers.add_parser("onboard", help="ëŒ€í™”í˜•ìœ¼ë¡œ ì±—ë´‡ ì„¤ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    subparsers.add_parser("setup-db", help="Oracle DBì— í…Œì´ë¸”ê³¼ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    crawl_parser = subparsers.add_parser("crawl", help="ë¸”ë¡œê·¸ ê²Œì‹œê¸€ì„ í¬ë¡¤ë§í•˜ê³  ë³€ê²½ëœ ë‚´ìš©ë§Œ DBì— ë°˜ì˜í•©ë‹ˆë‹¤.")
    crawl_parser.add_argument("--max-posts", type=int, default=None, help="í¬ë¡¤ë§í•  ìµœëŒ€ ê²Œì‹œê¸€ ìˆ˜ (ê¸°ë³¸ê°’: ëª¨ë“  ê²Œì‹œê¸€)")
    ask_parser = subparsers.add_parser("ask", help="ì±—ë´‡ì—ê²Œ ì§ˆë¬¸í•©ë‹ˆë‹¤ (ë‹µë³€ ìºì‹± ê¸°ëŠ¥ í¬í•¨).")
    ask_parser.add_argument("question", type=str, help="AIì—ê²Œ í•  ì§ˆë¬¸")
    args = parser.parse_args()
    try:
        if args.command == "setup-db":
            db = OracleManager()
            db.reset_database() # setup_tables ëŒ€ì‹  reset_database í˜¸ì¶œ
            db.close()
        elif args.command == "onboard":
            onboard_command()
        elif args.command == "crawl":
            crawl_command(args)
        elif args.command == "ask":
            ask_command(args.question)
    except oracledb.Error as e:
        print(f"\nâŒ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: {e}\n  - .env íŒŒì¼ ë° Oracle Cloud ATP ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    except ValueError as e:
        print(f"\nâŒ ì„¤ì • ì˜¤ë¥˜: {e}")
    except Exception as e:
        print(f"\nâŒ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()
